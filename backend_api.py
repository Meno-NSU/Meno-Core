import codecs
import json
import logging
import os
import re
from collections import defaultdict, deque
from contextlib import asynccontextmanager
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from typing import Literal

import pytz
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from dateutil import parser as dtparser
from fastapi import FastAPI
from pydantic import BaseModel

from config import settings
from lightrag import QueryParam, LightRAG
from lightrag.utils import setup_logger
from link_correcter import LinkCorrecter
# from reference_searcher import ReferenceSearcher
from link_searcher import LinkSearcher
from pathlib import Path
from dataclasses import dataclass, asdict
from rag_engine import initialize_rag, SYSTEM_PROMPT_FOR_MENO, QUERY_MAX_TOKENS, TOP_K, resolve_anaphora, \
    explain_abbreviations, get_current_period

QUERY_MODE: Literal["local", "global", "hybrid", "naive", "mix"] = settings.query_mode

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s | %(levelname)s | %(message)s",
)
logger = logging.getLogger(__name__)

# user_id -> [{"role": "user"/"assistant", "content": "..."}]
dialogue_histories: Dict[str, List[Dict[str, str]]] = defaultdict(list)

SCORES_CACHE_FILE = os.getenv("SCORES_CACHE_FILE", "question_scores.json")


@dataclass
class UserQuestion:
    msg_id: str  # —É–Ω–∏–∫–∞–ª—å–Ω—ã–π id —Å–æ–±—ã—Ç–∏—è (chat_id + –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä)
    chat_id: str
    content: str
    created_at_utc: datetime  # always timezone-aware UTC
    tokens_est: int  # –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã (–¥–ª—è –≤–µ—Å–∞)
    is_question: bool
    answer: Optional[str] = None  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ
    model_score: Optional[float] = None  # <-- –æ—Ü–µ–Ω–∫–∞ 0..100 (–ø–æ –∏—Ç–æ–≥—É /pick_best_question)
    model_reason: Optional[str] = None  # <-- –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ


RECENT_QUESTIONS_BUFFER: deque[UserQuestion] = deque(maxlen=1000)
all_user_questions: list[UserQuestion] = []
# –§–∞–π–ª-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ
QUESTIONS_FILE = Path(os.getenv("QUESTIONS_FILE", "questions.ndjson"))


def _ensure_questions_file():
    QUESTIONS_FILE.parent.mkdir(parents=True, exist_ok=True)
    if not QUESTIONS_FILE.exists():
        QUESTIONS_FILE.touch()


def save_question_to_file(q: UserQuestion) -> None:
    """Append one record to NDJSON (atomic-like)."""
    _ensure_questions_file()
    with QUESTIONS_FILE.open("a", encoding="utf-8") as f:
        rec = asdict(q).copy()
        # datetime –≤ iso
        rec["created_at_utc"] = q.created_at_utc.isoformat()
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def load_questions_window(start_utc: datetime, end_utc: datetime) -> List[UserQuestion]:
    """Stream read; —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –æ–∫–Ω—É –≤—Ä–µ–º–µ–Ω–∏."""
    if not QUESTIONS_FILE.exists():
        return []
    out: List[UserQuestion] = []
    with QUESTIONS_FILE.open("r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            try:
                obj = json.loads(line)
                t = dtparser.parse(obj["created_at_utc"])
                if start_utc <= t < end_utc:
                    out.append(UserQuestion(
                        msg_id=obj["msg_id"],
                        chat_id=obj["chat_id"],
                        content=obj["content"],
                        created_at_utc=t,
                        tokens_est=obj.get("tokens_est", len(obj["content"])),
                        is_question=obj.get("is_question", True),
                        answer=obj.get("answer"),
                        model_score=obj.get("model_score"),
                        model_reason=obj.get("model_reason"),
                    ))
            except Exception:
                logger.exception("Failed to parse questions.ndjson line")
    # –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    out.sort(key=lambda q: q.created_at_utc)
    return out


async def clear_rag_cache():
    """Clear LightRAG cache"""
    try:
        current_time = datetime.now(pytz.timezone("Asia/Novosibirsk"))
        logger.info(
            f"‚è∞ Clearing cache at: {current_time.strftime('%Y-%m-%d %H:%M:%S %Z%z')}")

        await rag_instance.aclear_cache()
        logger.info("‚úÖ LightRAG cache cleared successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to clear cache: {str(e)}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    global rag_instance, abbreviations, ref_searcher, ref_corrector, scheduler
    setup_logger("light_rag_log", "WARNING", False, str(settings.log_file_path))
    rag_instance = await initialize_rag()
    # ref_searcher = ReferenceSearcher(URLS_FNAME, model_name=LOCAL_EMBEDDER_NAME, threshold=0.75)
    if settings.enable_links_addition:
        ref_searcher = LinkSearcher(settings.urls_path, rag_instance, settings.top_k,
                                    dist_threshold=settings.dist_threshold, max_links=settings.max_links)
    if settings.enable_links_correction:
        ref_corrector = LinkCorrecter(settings.urls_path, settings.correct_dist_threshold)
    scheduler = AsyncIOScheduler(timezone="Asia/Novosibirsk")  # timezone
    # Clear cache daily at 00:00
    scheduler.add_job(
        clear_rag_cache,
        trigger=CronTrigger(hour=0, minute=0),
        name="clear_rag_cache_daily"
    )
    scheduler.start()
    logger.info("‚è∞ Cache-clearing scheduler started")
    try:
        with codecs.open(settings.abbreviations_file, mode='r', encoding='utf-8') as fp:
            abbreviations = json.load(fp)
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π: {len(abbreviations)}")
    except Exception as e:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π")

    yield  # <-- –∑–¥–µ—Å—å FastAPI –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç—É
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å await rag_instance.cleanup(), –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    # Shutdown scheduler on app exit
    scheduler.shutdown()
    logger.info("‚è∞ Cache-clearing scheduler stopped")


def _now_utc() -> datetime:
    return datetime.utcnow().replace(tzinfo=pytz.UTC)


def parse_time_range(start_str: str, end_str: str, tz_str: str) -> Tuple[datetime, datetime]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç/–≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '2025-08-27 12:00') –∏ tz (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Asia/Novosibirsk').
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –≤ UTC [start_utc, end_utc).
    """
    tz = pytz.timezone(tz_str)
    start_local = tz.localize(dtparser.parse(start_str, dayfirst=False))
    end_local = tz.localize(dtparser.parse(end_str, dayfirst=False))
    start_utc = start_local.astimezone(pytz.UTC)
    end_utc = end_local.astimezone(pytz.UTC)
    if end_utc <= start_utc:
        raise ValueError("end must be after start")
    return start_utc, end_utc


# –î–û–ë–ê–í–¨ —Ä—è–¥–æ–º —Å —É—Ç–∏–ª–∏—Ç–∞–º–∏
def _build_selection_prompt(candidates: list[UserQuestion]) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ–º user-–ø—Ä–æ–º–ø—Ç. –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±—É–¥–µ—Ç —Å—Ç—Ä–æ–≥–æ: "–í—ã–±–µ—Ä–∏ –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å".
    –ü—Ä–æ—Å–∏–º –≤–µ—Ä–Ω—É—Ç—å JSON ‚Äî —á—Ç–æ–±—ã –ª–µ–≥–∫–æ –ø–∞—Ä—Å–∏—Ç—å.
    """
    lines = []
    lines.append(
        "–ù–∏–∂–µ –¥–∞–Ω —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤. "
        "–í—ã–±–µ—Ä–∏ —Ä–æ–≤–Ω–æ –û–î–ò–ù –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å, –æ—Ü–µ–Ω–∏–≤–∞—è —è—Å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –Ω–æ–≤–∏–∑–Ω—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–∏—Ö –≤ —Å–ø–∏—Å–∫–µ. "
        "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ –ø—Ä–µ–ø–∞–º–±—É–ª—ã –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, —Ñ–æ—Ä–º–∞—Ç:\n"
        '{"winner_msg_id":"<msg_id>", "reason":"<–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º>"}\n'
        "–°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:"
    )
    for i, q in enumerate(candidates, 1):
        lines.append(
            f'{i}) msg_id="{q.msg_id}" | chat_id="{q.chat_id}" | time_utc="{q.created_at_utc.isoformat()}"\n'
            f'   {q.content}'
        )
    return "\n".join(lines)


app = FastAPI(lifespan=lifespan)
rag_instance: LightRAG
abbreviations = {}


class ChatRequest(BaseModel):
    chat_id: str
    message: str


class ChatResponse(BaseModel):
    chat_id: str
    response: str


class ResetRequest(BaseModel):
    chat_id: str


class ResetResponse(BaseModel):
    chat_id: str
    status: str


class CandidateItem(BaseModel):
    rank: int
    msg_id: str
    chat_id: str
    content: str
    answer: Optional[str] = None  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ
    created_at_iso: str
    is_question: bool
    prescore: Optional[float] = None
    model_score: Optional[float] = None  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ
    model_reason: Optional[str] = None  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ


class PickBestRequest(BaseModel):
    start: str
    end: str
    tz: str = "Asia/Novosibirsk"
    candidate_limit: int = 200
    use_prescoring: bool = False
    dedupe: bool = False
    # –Ω–æ–≤–æ–µ:
    scoring_criteria: str = (
        "- –ù–∞—Å–∫–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω –≤–æ–ø—Ä–æ—Å –¥–ª—è —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏;\n"
        "- –°–∫–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ–º –æ–Ω –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç –∏ –Ω–∞—Å–∫–æ–ª—å–∫–æ –≥–ª—É–±–æ–∫–æ;\n"
        "- –Ø—Å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞;\n"
        "- –ù–æ–≤–∏–∑–Ω–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç–∏–ø–∏—á–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏."
    )
    do_final_llm_selection: bool = True  # –µ—Å–ª–∏ False ‚Äî –ø–æ–±–µ–¥–∏—Ç–µ–ª—å = argmax(score)


class PickBestResponse(BaseModel):
    winner_msg_id: str | None
    winner_content: str | None
    model_reason: str | None
    raw_model_output: str | None
    candidates_count: int
    candidates: List[CandidateItem]  # <-- –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    print(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –æ—Ç {request.chat_id}: {request.message}")
    global rag_instance

    if rag_instance is None:
        raise RuntimeError("RAG is not initialized.")

    try:
        chat_id = request.chat_id
        query = request.message.strip()
        created_at = _now_utc()
        user_question = UserQuestion(
            msg_id=f"{chat_id}:{created_at.timestamp()}",
            chat_id=chat_id,
            content=query,
            created_at_utc=created_at,
            tokens_est=len(query),
            is_question=True
        )
        all_user_questions.append(user_question)
        logger.info(f"New request from user {request.chat_id}: {query}")
        history = dialogue_histories[chat_id][-4:]

        expanded_query = await explain_abbreviations(query, abbreviations)
        logger.info(f"Query after expanding abbreviations: {expanded_query}")

        resolved_query = await resolve_anaphora(expanded_query, history)
        logger.info(f"–ü–æ—Å–ª–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∞–Ω–∞—Ñ–æ—Ä: {resolved_query}")

        current_date_str = await get_current_period()
        formatted_system_prompt = SYSTEM_PROMPT_FOR_MENO.replace(
            "{current_date}",
            current_date_str
        )
        logger.info(f"Formatted system prompt: {formatted_system_prompt}")

        response_text = await rag_instance.aquery(
            resolved_query,
            param=QueryParam(
                mode=QUERY_MODE,
                top_k=TOP_K,
                max_token_for_text_unit=QUERY_MAX_TOKENS,
                max_token_for_global_context=QUERY_MAX_TOKENS,
                max_token_for_local_context=QUERY_MAX_TOKENS,
                history_turns=len(history)
            ),
            system_prompt=formatted_system_prompt
        )
        # answer = ref_searcher.replace_references(response_text)
        answer = response_text
        if settings.enable_links_correction:
            answer = await ref_corrector.replace_markdown_links(answer)
        if settings.enable_links_addition:
            answer = await ref_searcher.get_formated_answer(resolved_query, answer)
        # answer = response_text
        dialogue_histories[chat_id].append({"role": "user", "content": query})
        dialogue_histories[chat_id].append(
            {"role": "assistant", "content": answer})
        logger.info(f"–û—Ç–≤–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –¥–ª—è {chat_id}: {answer}")
        try:
            user_question.answer = answer
            save_question_to_file(user_question)
        except Exception:
            logger.exception("Failed to persist question/answer to file")

        return ChatResponse(chat_id=request.chat_id, response=answer)
    except Exception as e:
        logger.exception(
            f"Error while processing request from user {request.chat_id}")
        return ChatResponse(chat_id=request.chat_id, response="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.")


@app.post("/clear_history", response_model=ResetResponse)
async def reset_history(request: ResetRequest):
    chat_id = request.chat_id

    if chat_id in dialogue_histories:
        dialogue_histories.pop(chat_id)
        logger.info(f"–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id}")
    else:
        logger.info(
            f"–ü–æ–ø—ã—Ç–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return ResetResponse(chat_id=chat_id, status="ok")


@app.post("/pick_best_question", response_model=PickBestResponse)
async def pick_best_question(req: PickBestRequest):
    """
    1) —á–∏—Ç–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ FILE –ø–æ –æ–∫–Ω—É [start, end)
    2) (–æ–ø—Ü.) –ø—Ä–µ—Å–∫–æ—Ä–∏–º/—Å—É–∑–∏–º –¥–æ candidate_limit (—É —Ç–µ–±—è –≤—ã–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    3) –ø—Ä–æ—Å–∏–º LLM –æ—Ü–µ–Ω–∏—Ç—å –ö–ê–ñ–î–´–ô –≤–æ–ø—Ä–æ—Å (0..100) –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    4) –¥–æ–ø. —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–±–µ–¥–∏—Ç–µ–ª—è –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é LLM (–∏–ª–∏ argmax)
    """
    global rag_instance
    try:
        start_utc, end_utc = parse_time_range(req.start, req.end, req.tz)

        # --- 1) –∏–∑ —Ñ–∞–π–ª–∞ (–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫)
        window: List[UserQuestion] = load_questions_window(start_utc, end_utc)
        if not window:
            return PickBestResponse(
                winner_msg_id=None, winner_content=None,
                model_reason=None, raw_model_output=None,
                candidates_count=0, candidates=[],
            )

        # --- 2) —Å—É–∑–∏—Ç—å (–µ—Å–ª–∏ –Ω–∞–¥–æ)
        candidates = window[: max(1, req.candidate_limit)]

        # --- 3) –æ—Ü–µ–Ω–∫–∞ –ö–ê–ñ–î–û–ì–û –≤–æ–ø—Ä–æ—Å–∞ (–æ–¥–Ω–∏–º –±–∞—Ç—á-–ø—Ä–æ–º–ø—Ç–æ–º)
        scoring_user_prompt = build_per_question_scoring_prompt(candidates, req.scoring_criteria)
        scoring_system_prompt = "–¢—ã —Å—Ç—Ä–æ–≥–∏–π —Å—É–¥—å—è. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."

        scoring_output = await rag_instance.aquery(
            scoring_user_prompt,
            param=QueryParam(
                mode=QUERY_MODE,
                top_k=0,
                max_token_for_text_unit=QUERY_MAX_TOKENS,
                max_token_for_global_context=QUERY_MAX_TOKENS,
                max_token_for_local_context=QUERY_MAX_TOKENS,
                history_turns=0,
            ),
            system_prompt=scoring_system_prompt
        )

        parsed_scores = extract_json(scoring_output)
        # –æ–∂–∏–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ [{msg_id, score, reason}]
        if isinstance(parsed_scores, list):
            reason_map: Dict[str, Tuple[Optional[float], Optional[str]]] = {}
            for obj in parsed_scores:
                mid = obj.get("msg_id")
                sc = obj.get("score")
                rs = obj.get("reason")
                try:
                    if sc is not None:
                        sc = float(sc)
                        sc = max(0.0, min(100.0, sc))
                except Exception:
                    sc = None
                if mid:
                    reason_map[mid] = (sc, rs)
            # –ø—Ä–∏—Å–≤–æ–∏–º
            for q in candidates:
                if q.msg_id in reason_map:
                    sc, rs = reason_map[q.msg_id]
                    q.model_score = sc
                    q.model_reason = rs
        else:
            logger.warning("LLM scoring JSON not parsed; leaving scores as None.")

        # --- 4) —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        winner_msg_id = None
        final_reason = None
        final_output_text = None

        if req.do_final_llm_selection:
            final_user_prompt = build_final_selection_prompt(candidates)
            final_system_prompt = "–í—ã–±–µ—Ä–∏ –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON-–æ–±—ä–µ–∫—Ç."

            final_output_text = await rag_instance.aquery(
                final_user_prompt,
                param=QueryParam(
                    mode=QUERY_MODE,
                    top_k=0,
                    max_token_for_text_unit=QUERY_MAX_TOKENS,
                    max_token_for_global_context=QUERY_MAX_TOKENS,
                    max_token_for_local_context=QUERY_MAX_TOKENS,
                    history_turns=0,
                ),
                system_prompt=final_system_prompt
            )

            obj = extract_json(final_output_text)
            if isinstance(obj, dict):
                winner_msg_id = obj.get("winner_msg_id")
                final_reason = obj.get("reason")
        else:
            # argmax –ø–æ score, tie-breaker: –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π tokens_est, –ø–æ—Ç–æ–º –±–æ–ª–µ–µ —Ä–∞–Ω–Ω–∏–π
            scored = [q for q in candidates if q.model_score is not None]
            if scored:
                scored.sort(key=lambda x: (x.model_score, x.tokens_est, -x.created_at_utc.timestamp()), reverse=True)
                winner_msg_id = scored[0].msg_id
                final_reason = "Auto-selected as highest scored question."
            else:
                # –µ—Å–ª–∏ –Ω–µ—Ç –æ—Ü–µ–Ω–æ–∫, fallback ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                winner_msg_id = candidates[-1].msg_id
                final_reason = "Fallback to latest question."

        winner_content = None
        if winner_msg_id:
            for q in candidates:
                if q.msg_id == winner_msg_id:
                    winner_content = q.content
                    break

        # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤—ã–¥–∞—á—É –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        candidates_response: List[CandidateItem] = []
        for idx, q in enumerate(candidates, start=1):
            candidates_response.append(
                CandidateItem(
                    rank=idx,
                    msg_id=q.msg_id,
                    chat_id=q.chat_id,
                    content=q.content,
                    answer=q.answer,
                    created_at_iso=q.created_at_utc.isoformat(),
                    is_question=q.is_question,
                    prescore=None,
                    model_score=(None if q.model_score is None else round(float(q.model_score), 2)),
                    model_reason=q.model_reason
                )
            )

        # –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ score/reason –≤ —Ñ–∞–π–ª (append –∫–∞–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏)
        # –í–∞—Ä–∏–∞–Ω—Ç –ø—Ä–æ—Å—Ç–æ–π: –∑–∞–ø–∏—Å–∞—Ç—å ¬´–∞–ø–¥–µ–π—Ç¬ª –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π (event sourcing).
        try:
            for q in candidates:
                if (q.model_score is not None) or (q.model_reason):
                    save_question_to_file(q)
        except Exception:
            logger.exception("Failed to append scored records to file")

        return PickBestResponse(
            winner_msg_id=winner_msg_id,
            winner_content=winner_content,
            model_reason=final_reason,
            raw_model_output=final_output_text or scoring_output,
            candidates_count=len(candidates),
            candidates=candidates_response
        )

    except Exception:
        logger.exception("pick_best_question failed")
        return PickBestResponse(
            winner_msg_id=None,
            winner_content=None,
            model_reason=None,
            raw_model_output=None,
            candidates_count=0,
            candidates=[],
        )


def build_per_question_scoring_prompt(candidates: List[UserQuestion], criteria: str) -> str:
    """
    –ü—Ä–æ—Å–∏–º –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É—Ç—å JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤:
    [{"msg_id":"...", "score": 0..100, "reason": "..."}]
    """
    lines = []
    lines.append(
        "–û—Ü–µ–Ω–∏ –ö–ê–ñ–î–´–ô –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã—Ö –Ω–∏–∂–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —à–∫–∞–ª–µ –æ—Ç 0 –¥–æ 100.\n"
        "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è:\n"
        f"{criteria.strip()}\n\n"
        "–ü—Ä–∞–≤–∏–ª–∞:\n"
        "- –û—Ü–µ–Ω–∏ –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ.\n"
        "- –°—Ç—Ä–æ–≥–æ –≤–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ —Å –æ–±—ä–µ–∫—Ç–∞–º–∏ –≤–∏–¥–∞ "
        '{"msg_id":"<msg_id>", "score": <int>, "reason":"<–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ>"} '
        "–≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–∞–∫–æ–º –¥–∞–Ω—ã –≤–æ–ø—Ä–æ—Å—ã.\n"
        "- –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON.\n\n"
        "–°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:"
    )
    for i, q in enumerate(candidates, 1):
        ans = q.answer or ""
        lines.append(
            f'{i}) msg_id="{q.msg_id}" | chat_id="{q.chat_id}" | time_utc="{q.created_at_utc.isoformat()}"\n'
            f'   –í–û–ü–†–û–°: {q.content}\n'
            f'   –û–¢–í–ï–¢:  {ans}'
        )
    return "\n".join(lines)


def build_final_selection_prompt(candidates: List[UserQuestion]) -> str:
    """
    –ü—Ä–æ—Å–∏–º –≤—ã–±—Ä–∞—Ç—å —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω winner —Å –∫—Ä–∞—Ç–∫–æ–π –ø—Ä–∏—á–∏–Ω–æ–π; —Å—Ç—Ä–æ–≥–∏–π JSON-–æ–±—ä–µ–∫—Ç.
    """
    lines = []
    lines.append(
        "–ù–∏–∂–µ ‚Äî —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤. –í—ã–±–µ—Ä–∏ –†–û–í–ù–û –û–î–ò–ù –ª—É—á—à–∏–π —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ—Å—Ç–∏ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏.\n"
        '–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –æ–±—ä–µ–∫—Ç –≤–∏–¥–∞: {"winner_msg_id":"<msg_id>", "reason":"<–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ>"}\n'
        "–°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:"
    )
    for i, q in enumerate(candidates, 1):
        sc = q.model_score
        rs = q.model_reason or ""
        lines.append(
            f'{i}) msg_id="{q.msg_id}" | score={sc if sc is not None else "NA"}\n'
            f'   –í–û–ü–†–û–°: {q.content}\n'
            f'   –û–¢–í–ï–¢:  {q.answer or ""}\n'
            f'   –û–ë–û–°–ù.: {rs}'
        )
    return "\n".join(lines)


def extract_json(s: str):
    """–¥–æ—Å—Ç–∞—ë–º –ø–µ—Ä–≤—ã–π JSON-–º–∞—Å—Å–∏–≤ –∏–ª–∏ –æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏"""
    try:
        m = re.search(r"\[\s*\{.*\}\s*\]|\{\s*\".*", s, flags=re.DOTALL)
        if not m:
            return None
        return json.loads(m.group(0))
    except Exception:
        logger.exception("Failed to parse JSON from model output")
        return None
