import codecs
import json
import logging
from collections import defaultdict, deque
from contextlib import asynccontextmanager
from dataclasses import dataclass
from datetime import datetime
from typing import List, Dict, Tuple, re, Optional
from typing import Literal
from dateutil import parser as dtparser

import pytz
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from fastapi import FastAPI
from pydantic import BaseModel

from config import settings
from lightrag import QueryParam, LightRAG
from lightrag.utils import setup_logger
from link_correcter import LinkCorrecter
# from reference_searcher import ReferenceSearcher
from link_searcher import LinkSearcher
from rag_engine import initialize_rag, SYSTEM_PROMPT_FOR_MENO, QUERY_MAX_TOKENS, TOP_K, resolve_anaphora, \
    explain_abbreviations, get_current_period

QUERY_MODE: Literal["local", "global", "hybrid", "naive", "mix"] = settings.query_mode

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s | %(levelname)s | %(message)s",
)
logger = logging.getLogger(__name__)

# user_id -> [{"role": "user"/"assistant", "content": "..."}]
dialogue_histories: Dict[str, List[Dict[str, str]]] = defaultdict(list)


@dataclass
class UserQuestion:
    msg_id: str  # —É–Ω–∏–∫–∞–ª—å–Ω—ã–π id —Å–æ–±—ã—Ç–∏—è (–º–æ–∂–Ω–æ chat_id + –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä)
    chat_id: str
    content: str
    created_at_utc: datetime  # always timezone-aware UTC
    tokens_est: int  # –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã (–¥–ª—è –≤–µ—Å–∞)
    is_question: bool


RECENT_QUESTIONS_BUFFER: deque[UserQuestion] = deque(maxlen=1000)
all_user_questions: list[UserQuestion] = []


async def clear_rag_cache():
    """Clear LightRAG cache"""
    try:
        current_time = datetime.now(pytz.timezone("Asia/Novosibirsk"))
        logger.info(
            f"‚è∞ Clearing cache at: {current_time.strftime('%Y-%m-%d %H:%M:%S %Z%z')}")

        await rag_instance.aclear_cache()
        logger.info("‚úÖ LightRAG cache cleared successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to clear cache: {str(e)}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    global rag_instance, abbreviations, ref_searcher, ref_corrector, scheduler
    setup_logger("light_rag_log", "WARNING", False, str(settings.log_file_path))
    rag_instance = await initialize_rag()
    # ref_searcher = ReferenceSearcher(URLS_FNAME, model_name=LOCAL_EMBEDDER_NAME, threshold=0.75)
    if settings.enable_links_addition:
        ref_searcher = LinkSearcher(settings.urls_path, rag_instance, settings.top_k,
                                    dist_threshold=settings.dist_threshold, max_links=settings.max_links)
    if settings.enable_links_correction:
        ref_corrector = LinkCorrecter(settings.urls_path, settings.correct_dist_threshold)
    scheduler = AsyncIOScheduler(timezone="Asia/Novosibirsk")  # timezone
    # Clear cache daily at 00:00
    scheduler.add_job(
        clear_rag_cache,
        trigger=CronTrigger(hour=0, minute=0),
        name="clear_rag_cache_daily"
    )
    scheduler.start()
    logger.info("‚è∞ Cache-clearing scheduler started")
    try:
        with codecs.open(settings.abbreviations_file, mode='r', encoding='utf-8') as fp:
            abbreviations = json.load(fp)
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π: {len(abbreviations)}")
    except Exception as e:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π")

    yield  # <-- –∑–¥–µ—Å—å FastAPI –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç—É
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å await rag_instance.cleanup(), –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    # Shutdown scheduler on app exit
    scheduler.shutdown()
    logger.info("‚è∞ Cache-clearing scheduler stopped")


def _now_utc() -> datetime:
    return datetime.utcnow().replace(tzinfo=pytz.UTC)


def parse_time_range(start_str: str, end_str: str, tz_str: str) -> Tuple[datetime, datetime]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç/–≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '2025-08-27 12:00') –∏ tz (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Asia/Novosibirsk').
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –≤ UTC [start_utc, end_utc).
    """
    tz = pytz.timezone(tz_str)
    start_local = tz.localize(dtparser.parse(start_str, dayfirst=False))
    end_local = tz.localize(dtparser.parse(end_str, dayfirst=False))
    start_utc = start_local.astimezone(pytz.UTC)
    end_utc = end_local.astimezone(pytz.UTC)
    if end_utc <= start_utc:
        raise ValueError("end must be after start")
    return start_utc, end_utc


# –î–û–ë–ê–í–¨ —Ä—è–¥–æ–º —Å —É—Ç–∏–ª–∏—Ç–∞–º–∏
def _build_selection_prompt(candidates: list[UserQuestion]) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ–º user-–ø—Ä–æ–º–ø—Ç. –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±—É–¥–µ—Ç —Å—Ç—Ä–æ–≥–æ: "–í—ã–±–µ—Ä–∏ –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å".
    –ü—Ä–æ—Å–∏–º –≤–µ—Ä–Ω—É—Ç—å JSON ‚Äî —á—Ç–æ–±—ã –ª–µ–≥–∫–æ –ø–∞—Ä—Å–∏—Ç—å.
    """
    lines = []
    lines.append(
        "–ù–∏–∂–µ –¥–∞–Ω —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤. "
        "–í—ã–±–µ—Ä–∏ —Ä–æ–≤–Ω–æ –û–î–ò–ù –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å, –æ—Ü–µ–Ω–∏–≤–∞—è —è—Å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –Ω–æ–≤–∏–∑–Ω—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–∏—Ö –≤ —Å–ø–∏—Å–∫–µ. "
        "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –±–µ–∑ –ø—Ä–µ–ø–∞–º–±—É–ª—ã –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, —Ñ–æ—Ä–º–∞—Ç:\n"
        '{"winner_msg_id":"<msg_id>", "reason":"<–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º>"}\n'
        "–°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:"
    )
    for i, q in enumerate(candidates, 1):
        lines.append(
            f'{i}) msg_id="{q.msg_id}" | chat_id="{q.chat_id}" | time_utc="{q.created_at_utc.isoformat()}"\n'
            f'   {q.content}'
        )
    return "\n".join(lines)


app = FastAPI(lifespan=lifespan)
rag_instance: LightRAG
abbreviations = {}


class ChatRequest(BaseModel):
    chat_id: str
    message: str


class ChatResponse(BaseModel):
    chat_id: str
    response: str


class ResetRequest(BaseModel):
    chat_id: str


class ResetResponse(BaseModel):
    chat_id: str
    status: str


class CandidateItem(BaseModel):
    rank: int
    msg_id: str
    chat_id: str
    content: str
    created_at_iso: str
    is_question: bool
    prescore: Optional[float] = None  # None, –µ—Å–ª–∏ –ø—Ä–µ—Å–∫–æ—Ä –Ω–µ —Å—á–∏—Ç–∞–ª–∏


class PickBestRequest(BaseModel):
    start: str  # –Ω–∞–ø—Ä. "2025-08-27 12:00"
    end: str  # –Ω–∞–ø—Ä. "2025-08-27 18:00"
    tz: str = "Asia/Novosibirsk"
    # —á—Ç–æ–±—ã –Ω–µ —Å–ª–∞—Ç—å –≤ LLM —Å–æ—Ç–Ω–∏ —Å—Ç—Ä–æ–∫ ‚Äî –±–µ—Ä–µ–º —Ç–æ–ø –ø–æ –Ω–∞—à–µ–º—É —Å–∫–æ—Ä–µ—Ä—É –∏ —Ç–æ–ª—å–∫–æ –∏—Ö –æ—Ç–¥–∞—ë–º –º–æ–¥–µ–ª–∏
    candidate_limit: int = 200
    # –µ—Å–ª–∏ —Ö–æ—á–µ—à—å —Å–æ–≤—Å–µ–º –±–µ–∑ –Ω–∞—à–µ–≥–æ —Å–∫–æ—Ä–µ—Ä–∞ –∏ –ø—Ä–æ—Å—Ç–æ ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª ‚Äî –ø–æ—Å—Ç–∞–≤—å False
    use_prescoring: bool = False
    dedupe: bool = False  # –≤–ª–∏—è–µ—Ç –Ω–∞ –Ω–æ–≤–∏–∑–Ω—É –≤ —Å–∫–æ—Ä–µ—Ä–µ


class PickBestResponse(BaseModel):
    winner_msg_id: str | None
    winner_content: str | None
    model_reason: str | None
    raw_model_output: str | None
    candidates_count: int
    candidates: List[CandidateItem]  # <-- –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    print(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –æ—Ç {request.chat_id}: {request.message}")
    global rag_instance

    if rag_instance is None:
        raise RuntimeError("RAG is not initialized.")

    try:
        chat_id = request.chat_id
        query = request.message.strip()
        created_at = _now_utc()
        user_question = UserQuestion(
            msg_id=f"{chat_id}:{created_at.timestamp()}",
            chat_id=chat_id,
            content=query,
            created_at_utc=created_at,
            tokens_est=len(query),
            is_question=True
        )
        all_user_questions.append(user_question)
        logger.info(f"New request from user {request.chat_id}: {query}")
        history = dialogue_histories[chat_id][-4:]

        expanded_query = await explain_abbreviations(query, abbreviations)
        logger.info(f"Query after expanding abbreviations: {expanded_query}")

        resolved_query = await resolve_anaphora(expanded_query, history)
        logger.info(f"–ü–æ—Å–ª–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∞–Ω–∞—Ñ–æ—Ä: {resolved_query}")

        current_date_str = await get_current_period()
        formatted_system_prompt = SYSTEM_PROMPT_FOR_MENO.replace(
            "{current_date}",
            current_date_str
        )
        logger.info(f"Formatted system prompt: {formatted_system_prompt}")

        response_text = await rag_instance.aquery(
            resolved_query,
            param=QueryParam(
                mode=QUERY_MODE,
                top_k=TOP_K,
                max_token_for_text_unit=QUERY_MAX_TOKENS,
                max_token_for_global_context=QUERY_MAX_TOKENS,
                max_token_for_local_context=QUERY_MAX_TOKENS,
                history_turns=len(history)
            ),
            system_prompt=formatted_system_prompt
        )
        # answer = ref_searcher.replace_references(response_text)
        answer = response_text
        if settings.enable_links_correction:
            answer = await ref_corrector.replace_markdown_links(answer)
        if settings.enable_links_addition:
            answer = await ref_searcher.get_formated_answer(resolved_query, answer)
        # answer = response_text
        dialogue_histories[chat_id].append({"role": "user", "content": query})
        dialogue_histories[chat_id].append(
            {"role": "assistant", "content": answer})
        logger.info(f"–û—Ç–≤–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –¥–ª—è {chat_id}: {answer}")

        return ChatResponse(chat_id=request.chat_id, response=answer)
    except Exception as e:
        logger.exception(
            f"Error while processing request from user {request.chat_id}")
        return ChatResponse(chat_id=request.chat_id, response="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.")


@app.post("/clear_history", response_model=ResetResponse)
async def reset_history(request: ResetRequest):
    chat_id = request.chat_id

    if chat_id in dialogue_histories:
        dialogue_histories.pop(chat_id)
        logger.info(f"–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id}")
    else:
        logger.info(
            f"–ü–æ–ø—ã—Ç–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return ResetResponse(chat_id=chat_id, status="ok")


@app.post("/pick_best_question", response_model=PickBestResponse)
async def pick_best_question(req: PickBestRequest):
    """
    1) —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ–∫–Ω—É [start, end) –≤ req.tz
    2) (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ø—Ä–µ—Å–∫–æ—Ä–∏–º –∏ –≤–æ–∑—å–º—ë–º —Ç–æ–ø-N –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    3) –æ—Ç–ø—Ä–∞–≤–∏–º —Å–ø–∏—Å–æ–∫ –≤ LLM —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º "–í—ã–±–µ—Ä–∏ –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å"
    4) —Ä–∞—Å–ø–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç JSON –∏ –≤–µ—Ä–Ω—ë–º msg_id –∏ —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
    """
    global rag_instance

    try:
        start_utc, end_utc = parse_time_range(req.start, req.end, req.tz)

        window = [q for q in all_user_questions if start_utc <= q.created_at_utc < end_utc]
        if not window:
            return PickBestResponse(
                winner_msg_id=None,
                winner_content=None,
                model_reason=None,
                raw_model_output=None,
                candidates_count=0,
                candidates=[],
            )
        candidates_list = window[: max(1, req.candidate_limit)]
        candidates_response: List[CandidateItem] = []
        for idx, q in enumerate(candidates_list, start=1):
            candidates_response.append(
                CandidateItem(rank=idx, msg_id=q.msg_id, chat_id=q.chat_id, content=q.content,
                              created_at_iso=q.created_at_utc.isoformat(), is_question=q.is_question)
            )

        # –ø—Ä–µ—Å–∫—Ä–∏–Ω–∏–Ω–≥ –ø–æ –Ω–∞—à–µ–º—É —Å–∫–æ—Ä–µ—Ä—É, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
        candidates: list[UserQuestion]
        # –ë–µ–∑ –ø—Ä–µ—Å–∫–æ—Ä–∞ –±–µ—Ä—ë–º –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–≤—ã–µ N –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–∏–ª–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–π –∫–∞–∫ —Ç–µ–±–µ —É–¥–æ–±–Ω–æ)
        window.sort(key=lambda q: q.created_at_utc)
        candidates = window[: max(1, req.candidate_limit)]

        user_prompt = _build_selection_prompt(candidates)
        system_prompt = "–í—ã–±–µ—Ä–∏ –Ω–∞–∏–ª—É—á—à–∏–π –≤–æ–ø—Ä–æ—Å"

        # –í—ã–∑–æ–≤ —Ç–≤–æ–µ–π LLM. –î–ª—è –≤—ã–±–æ—Ä–∞ —Ç—É—Ç –Ω–µ –Ω—É–∂–µ–Ω –≥–ª–æ–±–∞–ª—å–Ω—ã–π/–ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∂–∏–º "naive".
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã top_k/–º–∞–∫—Å. —Ç–æ–∫–µ–Ω—ã –≤—ã—Å—Ç–∞–≤–ª—è—é –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏.
        llm_output = await rag_instance.aquery(
            user_prompt,
            param=QueryParam(
                mode="naive",
                top_k=0,
                max_token_for_text_unit=256,
                max_token_for_global_context=256,
                max_token_for_local_context=256,
                history_turns=0,
            ),
            system_prompt=system_prompt
        )

        # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ (–æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º ‚Äî –Ω–æ —Å—Ç–∞—Ä–∞–µ–º—Å—è)
        winner_msg_id = None
        model_reason = None
        try:
            # –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –æ–±–µ—Ä–Ω—É—Ç—å —á—Ç–æ-—Ç–æ –µ—â—ë ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –ø–µ—Ä–≤—ã–π JSON-–æ–±—ä–µ–∫—Ç
            match = re.search(r"\{.*\}", llm_output, flags=re.DOTALL)
            if match:
                data = json.loads(match.group(0))
                winner_msg_id = data.get("winner_msg_id")
                model_reason = data.get("reason")
        except Exception:
            logger.exception("Failed to parse LLM JSON output")

        # –Ω–∞—Ö–æ–¥–∏–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –ø–æ msg_id
        winner_content = None
        if winner_msg_id:
            for q in candidates:  # —Å—É–∂–∞–µ–º –ø–æ–∏—Å–∫ –¥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                if q.msg_id == winner_msg_id:
                    winner_content = q.content
                    break

        return PickBestResponse(
            winner_msg_id=winner_msg_id,
            winner_content=winner_content,
            model_reason=model_reason,
            raw_model_output=llm_output,
            candidates_count=len(candidates),
            candidates=candidates_response
        )

    except Exception:
        logger.exception("pick_best_question failed")
        return PickBestResponse(
            winner_msg_id=None,
            winner_content=None,
            model_reason=None,
            raw_model_output=None,
            candidates_count=0,
            candidates=[],
        )